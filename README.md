## 1. 프로젝트 개요

한국어 텍스트를 대상으로 **데이터 증강 기반 스타일 변환(Text Style Transfer)** 모델을 구축하는 프로젝트입니다.
기존 LLM에 LoRA 파인튜닝을 적용하여 **원문 의미는 유지하면서 목표 스타일로 변환**하는 모델을 만드는 것을 목표로 합니다.

## 2. 주요 아이디어 및 파이프라인

### 2.1 입력 데이터 준비 각자@

*   **현재 스타일(Current style)** 문장 여러 개
*   **목표 스타일(Target style)** 문장 여러 개
*   이때 두 스타일 간 문장은 **pair가 아님**(비정렬 상태)

# 2.2 데이터 증강(Augmentation) @

두 스타일 각각에 대해 동일한 증강 절차를 수행합니다.

#### (1) 문장 → 단어(토큰) 단위로 분해

*   공백 기준 분할
*   불필요한 기호 제거

#### (2) 단어들을 조합하여 새로운 문장 생성

*   조합 시 다음 기준 만족:
    *   **자연스러운 문장인지 체크** (언어모델 또는 문법 검사기 사용)
    *   **스타일 보존** (변형되어도 원래 스타일 특징은 유지)
    *   **의미 왜곡 최소화**

#### (3) 충분한 수의 새로운 문장 생성

*   현재 스타일 N개
*   목표 스타일 N개
*   구성 단어를 조합하여 **문장 수를 대폭 확장**

### 2.3 의미 기반 문장 매칭(Pairing)

증강된 두 스타일 문장 각각에 대해 임베딩을 추출합니다.

*   Sentence-BERT, KoSimCSE 등 한국어 임베딩 모델 활용
*   **의미적으로 가까운 문장들끼리 매칭**
*   즉, “같은 의미 + 스타일만 다른 쌍”으로 pair 데이터셋 생성

> (선택) 문장 증강 단계에서 이미 의미 기반 샘플링을 적용해 의미 차이가 너무 큰 문장은 조합 과정에서 제거할 수도 있습니다.

### 2.4 LLM 파인튜닝 (LoRA)

*   생성된 pair 데이터를 활용해 LLM을 **LoRA 방식으로 파인튜닝**합니다.
*   입력: 원문 + 목표 스타일 조건
*   출력: 목표 스타일로 변환된 문장
*   작은 GPU로도 학습 가능하도록 경량화

### 2.5 추론(사용 단계)

스타일 변환을 사용할 때 다음 조합을 활용합니다.

*   **파인튜닝된 LoRA**
*   **few-shot 예시(prompt)** (few-shot 예시는 마찬가지로 데이터 증강 방식으로 확보 가능)

이 조합을 통해 **원문 의미 보존 + 목표 스타일 반영**을 수행합니다.

# 2.6 성능 평가 @

스타일 트랜스퍼 품질 측정을 위해 다음 지표를 활용합니다.

#### (1) 의미 보존

*   임베딩 기반 유사도(cosine similarity)

#### (2) 스타일 일관성

*   스타일 분류기(사전 학습) 사용하여 목표 스타일 확률 측정

#### (3) 문장 유창성

*   perplexity 기반 평가 또는 언어모델 점수
*   사람이 직접 평가하는 human eval도 가능

### (4) 종합 점수

*   의미 보존 / 스타일 강도 / 자연스러움 균형

## 3. 전체 파이프라인 요약

1.  **두 스타일 문장 수집 (비정렬)**
2.  **각 스타일별 문장 토큰화 후 단어 조합 기반 증강**
3.  **증강 문장 임베딩 추출**
4.  **의미 기반 매칭 → pair 생성**
5.  **이 pair로 LLM LoRA 학습**
6.  **few-shot & LoRA로 스타일 변환 수행**
7.  **유사도·스타일 분류·유창성으로 성능 평가**
